{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Part: 3 Supervised Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook showcases my attempts at building a supervised machine learning model that can predict the parties from their speeches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ybfJr8UvQbzh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVIYSTMuTmA9"
      },
      "source": [
        "Mount Google Drive to Read in the files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XqCKSSATqdj",
        "outputId": "46ae7359-c56d-4853-e5a1-587795acab79"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose the local or google file path depending on how you are running the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "celW3R9-Qrm0"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"/content/drive/MyDrive/CA4023/ParlVote+.csv\")\n",
        "df = pd.read_csv(\"../data/ParlVote+.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the model type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean and stem the speeches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\FX\n",
            "[nltk_data]     8320\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to C:\\Users\\FX\n",
            "[nltk_data]     8320\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\FX\n",
            "[nltk_data]     8320\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove common parliamentary terms\n",
        "parliamentay_stop_words = {\"hon\", \"would\", \"people\", \"member\", \"right\", \"friend\", \"bill\", \"house\", \"government\", \"minister\", \"gentleman\", \"lady\", \"mr\", \"speaker\", \"one\", \"members\", \"said\", \"many\", \"made\", \"time\", \"want\", \"us\", \"“\", \"”\", \"’\"}\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "updated_stop_words = stop_words.union(parliamentay_stop_words) # Can slightly degrade machine learning performance\n",
        "punctuation_translation = str.maketrans('', '', string.punctuation)\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Removing Punctuation\n",
        "    text = text.translate(punctuation_translation)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Removing Stopwords and lemmatization\n",
        "    #tokens = [lemmatizer.lemmatize(word)) for word in tokens if word not in stop_words]\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['ml_speech'] = df['speech'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        right hon gentleman recit catalogu two third c...\n",
            "1        sure whether occur right hon gentleman late wi...\n",
            "2        right hon gentleman leav subject prison tell u...\n",
            "3        thank right hon member penrith border generos ...\n",
            "4        thank right hon friend give way congratul appo...\n",
            "                               ...                        \n",
            "33306    point hon gentleman eu nation given vote scott...\n",
            "33307    point order madam deputi speaker hope move man...\n",
            "33308    point order mr speaker today ’ vote lay preced...\n",
            "33309    point order mr speaker know sometim uncomfort ...\n",
            "33310    point order mr speaker three half year liber d...\n",
            "Name: ml_speech, Length: 33311, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['ml_speech'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stratified Samplings\n",
        "y = df['party']\n",
        "\n",
        "# Use stratified sampling to split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=62, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_df['ml_speech'], test_df['ml_speech'], train_df['party'], test_df['party']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(y_test, y_pred):\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Overall Accuracy: {overall_accuracy}\\n\")\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for each class\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use TfidfVectorizer to turn the words into numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=250000, ngram_range=(1,4), stop_words=\"english\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train the model and calculate the metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "250,000 features\n",
        "ngram range  1-4\n",
        "remove stop words\n",
        "stem\n",
        "max iter 1000\n",
        "C = 10\n",
        "is the best so far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 0.6462554404922708\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "                          alliance       0.00      0.00      0.00         2\n",
            "                      conservative       0.66      0.77      0.71      2700\n",
            "                               dup       0.51      0.26      0.34       116\n",
            "                             green       1.00      0.04      0.08        23\n",
            "                       independent       0.67      0.09      0.15        46\n",
            "          independent-conservative       0.00      0.00      0.00         1\n",
            "       independent-ulster-unionist       0.00      0.00      0.00         2\n",
            "                            labour       0.64      0.75      0.69      2619\n",
            "                labourco-operative       0.20      0.01      0.01       156\n",
            "                  liberal-democrat       0.60      0.24      0.34       572\n",
            "                       plaid-cymru       0.57      0.12      0.20        67\n",
            "                           respect       0.00      0.00      0.00         1\n",
            "           scottish-national-party       0.62      0.24      0.35       286\n",
            "social-democratic-and-labour-party       1.00      0.05      0.10        38\n",
            "                              ukip       0.00      0.00      0.00         3\n",
            "                               uup       0.50      0.13      0.21        31\n",
            "\n",
            "                          accuracy                           0.65      6663\n",
            "                         macro avg       0.44      0.17      0.20      6663\n",
            "                      weighted avg       0.63      0.65      0.62      6663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#model = LogisticRegression(multi_class=\"multinomial\", max_iter=500, class_weights=\"balanced\")\n",
        "\n",
        "model = LogisticRegression(multi_class=\"multinomial\", max_iter=1000, C=10)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "calculate_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use Cross-Validation to optimise the model's parameters.\n",
        "\n",
        "I have commented this out as it takes a long time to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Create the pipeline with TfidfVectorizer and LogisticRegression\n",
        "# pipeline = Pipeline([\n",
        "#     ('tfidf', TfidfVectorizer(max_features=100000, stop_words=\"english\")),\n",
        "#     ('model', LogisticRegression(multi_class='multinomial'))\n",
        "# ])\n",
        "\n",
        "# # Set up the parameter grid\n",
        "# param_grid = {\n",
        "#     'tfidf__ngram_range': [(1, 3), (1, 4)],\n",
        "#     'model__C': [0.1, 1, 10]\n",
        "# }\n",
        "\n",
        "# # Use accuracy as the scoring metric\n",
        "# scorer = make_scorer(accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform grid search with 4-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                                        TfidfVectorizer(max_features=100000,\n",
              "                                                        stop_words=&#x27;english&#x27;)),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        LogisticRegression(multi_class=&#x27;multinomial&#x27;))]),\n",
              "             n_jobs=4,\n",
              "             param_grid={&#x27;model__C&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;tfidf__ngram_range&#x27;: [(1, 3), (1, 4)]},\n",
              "             scoring=make_scorer(accuracy_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                                        TfidfVectorizer(max_features=100000,\n",
              "                                                        stop_words=&#x27;english&#x27;)),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        LogisticRegression(multi_class=&#x27;multinomial&#x27;))]),\n",
              "             n_jobs=4,\n",
              "             param_grid={&#x27;model__C&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;tfidf__ngram_range&#x27;: [(1, 3), (1, 4)]},\n",
              "             scoring=make_scorer(accuracy_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_features=100000, stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;model&#x27;, LogisticRegression(multi_class=&#x27;multinomial&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=100000, stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('tfidf',\n",
              "                                        TfidfVectorizer(max_features=100000,\n",
              "                                                        stop_words='english')),\n",
              "                                       ('model',\n",
              "                                        LogisticRegression(multi_class='multinomial'))]),\n",
              "             n_jobs=4,\n",
              "             param_grid={'model__C': [0.1, 1, 10],\n",
              "                         'tfidf__ngram_range': [(1, 3), (1, 4)]},\n",
              "             scoring=make_scorer(accuracy_score))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # n_jobs will determine how much of your processor is used\n",
        "# grid_search = GridSearchCV(pipeline, param_grid, cv=4, scoring=scorer, n_jobs=4)\n",
        "# grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters:  {'model__C': 10, 'tfidf__ngram_range': (1, 4)}\n",
            "Best Accuracy: 0.62\n",
            "Overall Accuracy: 0.6426534594026715\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "                          alliance       1.00      0.50      0.67         2\n",
            "                      conservative       0.66      0.76      0.71      2700\n",
            "                               dup       0.53      0.27      0.36       116\n",
            "                             green       0.75      0.13      0.22        23\n",
            "                       independent       0.67      0.13      0.22        46\n",
            "          independent-conservative       0.00      0.00      0.00         1\n",
            "       independent-ulster-unionist       0.00      0.00      0.00         2\n",
            "                            labour       0.64      0.74      0.69      2619\n",
            "                labourco-operative       0.36      0.03      0.06       156\n",
            "                  liberal-democrat       0.52      0.27      0.35       572\n",
            "                       plaid-cymru       0.71      0.15      0.25        67\n",
            "                           respect       0.00      0.00      0.00         1\n",
            "           scottish-national-party       0.61      0.29      0.40       286\n",
            "social-democratic-and-labour-party       0.62      0.13      0.22        38\n",
            "                              ukip       0.00      0.00      0.00         3\n",
            "                               uup       0.40      0.19      0.26        31\n",
            "\n",
            "                          accuracy                           0.64      6663\n",
            "                         macro avg       0.47      0.22      0.27      6663\n",
            "                      weighted avg       0.63      0.64      0.62      6663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # Print the best parameters and corresponding accuracy\n",
        "# print(\"Best Parameters: \", grid_search.best_params_)\n",
        "# print(\"Best Accuracy: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "# # Make predictions using the best model\n",
        "# y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# # Calculate metrics on the test set\n",
        "# calculate_metrics(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Class weights can help the model to identify underrepresented classes.\n",
        "\n",
        "In this case they lower the accuracy, but increase the macro average, recall and f1_score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 0.625093801590875\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "                          alliance       0.00      0.00      0.00         2\n",
            "                      conservative       0.69      0.70      0.70      2700\n",
            "                               dup       0.46      0.41      0.43       116\n",
            "                             green       0.46      0.26      0.33        23\n",
            "                       independent       0.29      0.15      0.20        46\n",
            "          independent-conservative       0.00      0.00      0.00         1\n",
            "       independent-ulster-unionist       0.00      0.00      0.00         2\n",
            "                            labour       0.68      0.67      0.67      2619\n",
            "                labourco-operative       0.20      0.12      0.15       156\n",
            "                  liberal-democrat       0.38      0.45      0.41       572\n",
            "                       plaid-cymru       0.40      0.31      0.35        67\n",
            "                           respect       0.00      0.00      0.00         1\n",
            "           scottish-national-party       0.44      0.47      0.45       286\n",
            "social-democratic-and-labour-party       0.58      0.29      0.39        38\n",
            "                              ukip       0.00      0.00      0.00         3\n",
            "                               uup       0.31      0.42      0.36        31\n",
            "\n",
            "                          accuracy                           0.63      6663\n",
            "                         macro avg       0.31      0.27      0.28      6663\n",
            "                      weighted avg       0.62      0.63      0.62      6663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "weight_model = LogisticRegression(multi_class=\"multinomial\", max_iter=250000, C=10, class_weight=\"balanced\")\n",
        "weight_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = weight_model.predict(X_test_tfidf)\n",
        "\n",
        "calculate_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **BILSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.layers import Dropout\n",
        "import numpy as np\n",
        "from keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the nth percentile of speech length to calculate word length of BILSTM input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "581.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate speech lengths\n",
        "speech_lengths = df['speech'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Calculate the percentile\n",
        "print(np.percentile(speech_lengths, 60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the average speech length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "330.2887634715259\n"
          ]
        }
      ],
      "source": [
        "mean_length = df['ml_speech'].apply(lambda x: len(x.split())).mean()\n",
        "print(mean_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do the stratified sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stratified Sampling\n",
        "X = df['ml_speech']  # Features\n",
        "y = df['party']  # Target variable\n",
        "\n",
        "# Use stratified sampling to split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=62, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=62, stratify = y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the size of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 129589\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Vocabulary size is the length of the word index + 1\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenize and pad the speeches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_words = 25000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length = 300\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert party labels to one hot vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "y_train_one_hot = label_binarizer.fit_transform(y_train)\n",
        "y_test_one_hot = label_binarizer.transform(y_test)\n",
        "y_val_one_hot = label_binarizer.transform(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replicate Sklearn's balanced class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 149.89375, 1: 0.1542275439860068, 2: 3.603215144230769, 3: 18.059487951807228, 4: 9.084469696969697, 5: 374.734375, 6: 249.82291666666666, 7: 0.15897099374270868, 8: 2.662411190053286, 9: 0.7287007778317939, 10: 6.193956611570248, 11: 374.734375, 12: 1.4581104085603114, 13: 11.021599264705882, 14: 149.89375, 15: 13.503941441441441}\n"
          ]
        }
      ],
      "source": [
        "class_weights = {}\n",
        "\n",
        "for party in np.unique(y_train):\n",
        "    occurrence = np.bincount(y_train == party)[1]\n",
        "    class_weights[party] = len(y_train) / (len(np.unique(y_train)) * occurrence)\n",
        "\n",
        "# Classes have to be represented by their index.\n",
        "class_indices = {class_name: index for index, class_name in enumerate(label_binarizer.classes_)}\n",
        "index_class_weights = {}\n",
        "for party, weight in class_weights.items():\n",
        "    index_class_weights[class_indices[party]] = weight\n",
        "\n",
        "class_weights\n",
        "print(index_class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 149.89375, 1: 0.1542275439860068, 2: 3.603215144230769, 3: 18.059487951807228, 4: 9.084469696969697, 5: 374.734375, 6: 249.82291666666666, 7: 0.15897099374270868, 8: 2.662411190053286, 9: 0.7287007778317939, 10: 6.193956611570248, 11: 374.734375, 12: 1.4581104085603114, 13: 11.021599264705882, 14: 149.89375, 15: 13.503941441441441}\n"
          ]
        }
      ],
      "source": [
        "class_indices = {class_name: index for index, class_name in enumerate(label_binarizer.classes_)}\n",
        "index_class_weights = {}\n",
        "for party, weight in class_weights.items():\n",
        "    index_class_weights[class_indices[party]] = weight\n",
        "\n",
        "class_weights\n",
        "print(index_class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build the BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 200\n",
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_length))\n",
        "bilstm_model.add(Bidirectional(LSTM(64)))  # return_sequences are needed to use multiple layers\n",
        "bilstm_model.add(Dropout(0.2))\n",
        "# bilstm_model.add(LSTM(32))  # Add another LSTM layer\n",
        "bilstm_model.add(Dense(units=len(label_binarizer.classes_), activation='softmax'))\n",
        "bilstm_model.compile('adam',loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:From c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "750/750 [==============================] - 69s 88ms/step - loss: 1.4145 - accuracy: 0.4276 - val_loss: 1.3413 - val_accuracy: 0.4702\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 66s 88ms/step - loss: 1.2496 - accuracy: 0.5377 - val_loss: 1.3057 - val_accuracy: 0.4968\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 66s 89ms/step - loss: 1.0556 - accuracy: 0.6316 - val_loss: 1.3304 - val_accuracy: 0.5066\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.8256 - accuracy: 0.7233 - val_loss: 1.5119 - val_accuracy: 0.4619\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 67s 89ms/step - loss: 0.6244 - accuracy: 0.7978 - val_loss: 1.7059 - val_accuracy: 0.4938\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1b795d6ce10>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#bilstm_model.fit(X_train_pad, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.1, class_weight=index_class_weights)\n",
        "bilstm_model.fit(X_train_pad, y_train_one_hot, epochs=5, batch_size=32, validation_data=(X_val_pad, y_val_one_hot))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209/209 [==============================] - 5s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the classes on the test set\n",
        "y_pred_one_hot = bilstm_model.predict(X_test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 0.4915203361849017\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "                          alliance       0.00      0.00      0.00         2\n",
            "                      conservative       0.55      0.54      0.55      2700\n",
            "                               dup       0.27      0.27      0.27       116\n",
            "                             green       0.00      0.00      0.00        23\n",
            "                       independent       0.00      0.00      0.00        46\n",
            "          independent-conservative       0.00      0.00      0.00         1\n",
            "       independent-ulster-unionist       0.00      0.00      0.00         2\n",
            "                            labour       0.51      0.62      0.56      2619\n",
            "                labourco-operative       0.06      0.01      0.01       156\n",
            "                  liberal-democrat       0.22      0.14      0.17       572\n",
            "                       plaid-cymru       0.08      0.01      0.02        67\n",
            "                           respect       0.00      0.00      0.00         1\n",
            "           scottish-national-party       0.24      0.27      0.25       286\n",
            "social-democratic-and-labour-party       0.00      0.00      0.00        38\n",
            "                              ukip       0.00      0.00      0.00         3\n",
            "                               uup       0.00      0.00      0.00        31\n",
            "\n",
            "                          accuracy                           0.49      6663\n",
            "                         macro avg       0.12      0.12      0.11      6663\n",
            "                      weighted avg       0.46      0.49      0.47      6663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Convert one-hot encoded predictions back to class labels\n",
        "\n",
        "y_pred = label_binarizer.inverse_transform(y_pred_one_hot)\n",
        "\n",
        "# Convert true labels to class labels\n",
        "y_true = label_binarizer.inverse_transform(y_test_one_hot)\n",
        "\n",
        "# Compute accuracy\n",
        "calculate_metrics(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ChatGPT Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the models on the sample used with chat_gpt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "chatgpt_samples = pd.read_csv(\"../data/chatgpt_samples.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "chatgpt_samples['ml_speech'] = chatgpt_samples['speech'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform the sample using the tfidf_vectorizer\n",
        "\n",
        "Make sure to use (max_features=250000, ngram_range=(1,4), stop_words=\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_chatgpt_tfidf = tfidf_vectorizer.transform(chatgpt_samples['ml_speech'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose one of the logistic regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 0.5666666666666667\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "           conservative       0.50      1.00      0.67         7\n",
            "                    dup       1.00      1.00      1.00         1\n",
            "                 labour       0.54      0.64      0.58        11\n",
            "     labourco-operative       0.00      0.00      0.00         3\n",
            "       liberal-democrat       1.00      0.33      0.50         6\n",
            "            plaid-cymru       0.00      0.00      0.00         1\n",
            "scottish-national-party       0.00      0.00      0.00         1\n",
            "\n",
            "               accuracy                           0.57        30\n",
            "              macro avg       0.43      0.42      0.39        30\n",
            "           weighted avg       0.55      0.57      0.50        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_chatgpt_tfidf)\n",
        "calculate_metrics(chatgpt_samples['party'], y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy: 0.43333333333333335\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "                      conservative       0.50      0.71      0.59         7\n",
            "                               dup       0.00      0.00      0.00         1\n",
            "                            labour       0.67      0.36      0.47        11\n",
            "                labourco-operative       0.00      0.00      0.00         3\n",
            "                  liberal-democrat       0.44      0.67      0.53         6\n",
            "                       plaid-cymru       0.00      0.00      0.00         1\n",
            "           scottish-national-party       0.00      0.00      0.00         1\n",
            "social-democratic-and-labour-party       0.00      0.00      0.00         0\n",
            "\n",
            "                          accuracy                           0.43        30\n",
            "                         macro avg       0.20      0.22      0.20        30\n",
            "                      weighted avg       0.45      0.43      0.42        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = weight_model.predict(X_chatgpt_tfidf)\n",
        "calculate_metrics(chatgpt_samples['party'], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert to BILSTM Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_chatgpt_seq = tokenizer.texts_to_sequences(chatgpt_samples['ml_speech'])\n",
        "y_chatgpt_one_hot = label_binarizer.transform(chatgpt_samples['party'])\n",
        "X_chatgpt_pad = pad_sequences(X_chatgpt_seq, maxlen=max_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "Overall Accuracy: 0.4\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "           conservative       0.42      0.71      0.53         7\n",
            "                    dup       1.00      1.00      1.00         1\n",
            "                 labour       0.36      0.36      0.36        11\n",
            "     labourco-operative       0.00      0.00      0.00         3\n",
            "       liberal-democrat       0.25      0.17      0.20         6\n",
            "            plaid-cymru       0.00      0.00      0.00         1\n",
            "scottish-national-party       0.50      1.00      0.67         1\n",
            "\n",
            "               accuracy                           0.40        30\n",
            "              macro avg       0.36      0.46      0.39        30\n",
            "           weighted avg       0.33      0.40      0.35        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\FX 8320\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred_one_hot = bilstm_model.predict(X_chatgpt_pad)\n",
        "\n",
        "y_pred = label_binarizer.inverse_transform(y_pred_one_hot)\n",
        "\n",
        "# Convert true labels to class labels\n",
        "y_true = label_binarizer.inverse_transform(y_chat_one_hot)\n",
        "\n",
        "# Compute accuracy\n",
        "calculate_metrics(y_true, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
